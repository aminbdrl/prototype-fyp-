import streamlit as st
import pandas as pd
import re
from seacrowd.loaders import MalaysiaTweets
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
import plotly.express as px
from datetime import datetime

# =====================================
# PAGE CONFIG
# =====================================
st.set_page_config(
    page_title="Kelantan Social Unity Sentiment Dashboard",
    layout="wide"
)

st.title("üìä Kelantan Social Unity Sentiment Analysis")
st.caption("Dataset: SEACrowd Malaysia Tweets (official loader)")

# =====================================
# TEXT CLEANING
# =====================================
def clean_text(text):
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = re.sub(r"http\S+|www\S+|@\w+|#\w+", "", text)
    text = re.sub(r"[^a-z\s']", "", text)
    return text.strip()

# =====================================
# KELANTAN KEYWORDS
# =====================================
KELANTAN_KEYWORDS = [
    "kelantan", "kelate", "kota bharu", "kotabharu", "kb",
    "tumpat", "pasir mas", "tanah merah", "machang",
    "kuala krai", "gua musang", "pasir puteh", "bachok",
    "jeli", "pengkalan chepa", "wakaf che yeh",
    "pantai cahaya bulan", "pcb", "pasar siti khadijah",
    "nasi kerabu", "nasi dagang", "laksam", "budu",
    "orang kelate", "oghe kelate", "demo kelate",
    "gapo", "mung", "kito"
]

def is_kelantan_related(text):
    if not isinstance(text, str):
        return False
    text = text.lower()
    return any(k in text for k in KELANTAN_KEYWORDS)

# =====================================
# LOAD SEACROWD DATASET & TRAIN MODEL
# =====================================
@st.cache_data(show_spinner=True)
def load_and_train():
    loader = MalaysiaTweets()
    records = []

    for sample in loader:
        if sample.text is not None and sample.label is not None:
            records.append({
                "text": sample.text,
                "label": sample.label
            })

    df = pd.DataFrame(records)

    df["clean_text"] = df["text"].apply(clean_text)

    vectorizer = TfidfVectorizer(
        max_features=5000,
        ngram_range=(1, 2)
    )

    X = vectorizer.fit_transform(df["clean_text"])
    y = df["label"]

    model = MultinomialNB()
    model.fit(X, y)

    return df, vectorizer, model

with st.spinner("Loading SEACrowd dataset & training sentiment model..."):
    df_all, vectorizer, model = load_and_train()

# Label mapping (SEACrowd standard)
LABEL_MAP = {
    0: "Negative",
    1: "Neutral",
    2: "Positive"
}

# =====================================
# SIDEBAR CONTROLS
# =====================================
st.sidebar.header("‚öôÔ∏è Analysis Controls")

tweet_limit = st.sidebar.slider(
    "Number of Tweets",
    min_value=50,
    max_value=500,
    value=200
)

time_window = st.sidebar.selectbox(
    "Time Window",
    options=[12, 24, 48, 72, 168],
    format_func=lambda x: {
        12: "Last 12 Hours",
        24: "Last 24 Hours",
        48: "Last 48 Hours",
        72: "Last 72 Hours",
        168: "Last 7 Days"
    }[x]
)

# =====================================
# RUN ANALYSIS
# =====================================
if st.sidebar.button("üîÑ Run Analysis"):

    df = df_all.copy()

    # Filter Kelantan-related tweets
    df = df[df["text"].apply(is_kelantan_related)]

    if df.empty:
        st.warning("‚ö†Ô∏è No Kelantan-related tweets found.")
        st.stop()

    # Limit tweets
    df = df.head(tweet_limit)

    # Simulated short-term timestamps (academic-safe)
    df["date"] = pd.date_range(
        end=datetime.now(),
        periods=len(df),
        freq="H"
    )

    # Predict sentiment
    df["predicted"] = model.predict(
        vectorizer.transform(df["clean_text"])
    )
    df["sentiment"] = df["predicted"].map(LABEL_MAP)

    # =====================================
    # METRICS
    # =====================================
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("Total Tweets", len(df))
    with col2:
        st.metric("Positive",
                  f"{(df['sentiment']=='Positive').mean()*100:.1f}%")
    with col3:
        st.metric("Negative",
                  f"{(df['sentiment']=='Negative').mean()*100:.1f}%")

    # =====================================
    # TABLE
    # =====================================
    st.subheader("üìã Kelantan Tweet Sentiment")
    st.dataframe(
        df[["date", "text", "sentiment"]],
        use_container_width=True
    )

    # =====================================
    # PIE CHART
    # =====================================
    st.subheader("üìä Sentiment Distribution")
    fig_pie = px.pie(
        df,
        names="sentiment",
        hole=0.4
    )
    st.plotly_chart(fig_pie, use_container_width=True)

    # =====================================
    # TREND ANALYSIS
    # =====================================
    st.subheader("üìà Sentiment Trend")

    if time_window <= 48:
        df["time_group"] = df["date"].dt.floor("H")
    else:
        df["time_group"] = df["date"].dt.floor("D")

    trend = (
        df.groupby(["time_group", "sentiment"])
        .size()
        .reset_index(name="count")
    )

    fig_trend = px.line(
        trend,
        x="time_group",
        y="count",
        color="sentiment",
        markers=True
    )
    st.plotly_chart(fig_trend, use_container_width=True)

else:
    st.info("üëà Click **Run Analysis** to start")

    with st.expander("‚ÑπÔ∏è About This System"):
        st.markdown("""
**Kelantan Social Unity Sentiment Analysis Dashboard**

‚Ä¢ Dataset: **SEACrowd Malaysia Tweets (official loader)**  
‚Ä¢ Approach: **Supervised Machine Learning**  
‚Ä¢ Model: **TF-IDF + Multinomial Naive Bayes**  
‚Ä¢ Focus: **Kelantan-related social sentiment**  
‚Ä¢ Time Window: **Short-term (12 hours ‚Äì 7 days)**  

This system avoids dataset scripts and local files by using the official
SEACrowd Python loader, ensuring stability and academic reproducibility.
""")
